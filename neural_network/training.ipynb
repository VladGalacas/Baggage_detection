{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1_GB9-UE9qj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "527956ec-5734-4cd0-ad21-5c3163807913"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import shutil\n",
    "from random import randint, shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import tqdm\n",
    "import yaml\n",
    "\n",
    "%matplotlib inline\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8pUdOkaX076"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/Baggage/positive-Annotation.zip\n",
    "\n",
    "os.mkdir('dataset')\n",
    "!unzip /content/drive/MyDrive/Baggage/positive_JPEGImage.zip -d /content/dataset\n",
    "\n",
    "os.mkdir('dataset_negative')\n",
    "!unzip /content/drive/MyDrive/Baggage/negative_JPEGImage.zip -d /content/dataset_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GY49VRrcb9PL"
   },
   "source": [
    "# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwoYEfAbbz2N"
   },
   "outputs": [],
   "source": [
    "CLASSES = ('Gun', 'Knife', 'Wrench', 'Pliers', 'Scissors')\n",
    "# CLASSES = ('Gun', 'Knife', 'Wrench', 'Pliers', 'Scissors', 'Hammer')\n",
    "# CLASSES = ('Gun', 'Knife', 'Wrench', 'Pliers','Hammer', 'Scissors')\n",
    "\n",
    "PATH_POSITIVE_IMGS = '/content/dataset'\n",
    "PATH_NEGATIVE_IMGS='/content/dataset_negative'\n",
    "\n",
    "# INCLUDE_NO_OBJECT_IMGS: False, –µ—Å–ª–∏ –Ω–µ –≤–∫–ª—é—á–∞—Ç—å –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è,\n",
    "# –≤ –∏–Ω–æ–º —Å–ª—É—á–∞–µ - –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç 0 –¥–æ 1 (–¥–æ–ª—è –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –≤—Å–µ–≥–æ –∏—Ö 10736 —à—Ç.)\n",
    "INCLUDE_NO_OBJECT_IMGS = 0.2\n",
    "\n",
    "# TEST_SIZE, VAL_SIZE: –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç 0 –¥–æ 1 (–¥–æ–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö \n",
    "# –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π) –æ—Ç –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –æ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –Ω–µ –≤–∫–ª—é—á–∞—é—â–∏—Ö\n",
    "# —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ\n",
    "TEST_SIZE = 0.3\n",
    "VAL_SIZE = 0.25\n",
    "\n",
    "# RESIZE_IMAGES (int/bool): False, –∏–ª–∏ —Ä–∞–∑–º–µ—Ä, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –æ–±—Ä–µ–∂—É—Ç—Å—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è \n",
    "# (–æ–±—ã—á–Ω–æ - 640)\n",
    "RESIZE_IMAGES = False\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKVyPa436OCF"
   },
   "source": [
    "## –°–∫–∞—á–∏–≤–∞–Ω–∏–µ YOLOv7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-VApq0t5AHi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f4a12550-1373-4794-e7f2-0726c97716b2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'yolov7'...\n",
      "remote: Enumerating objects: 1133, done.\u001B[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001B[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001B[K\n",
      "remote: Total 1133 (delta 0), reused 1 (delta 0), pack-reused 1130\u001B[K\n",
      "Receiving objects: 100% (1133/1133), 69.94 MiB | 16.50 MiB/s, done.\n",
      "Resolving deltas: 100% (523/523), done.\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 4)) (3.7.1)\n",
      "Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 5)) (1.22.4)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 6)) (4.6.0.66)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 7)) (8.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 8)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 9)) (2.27.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 10)) (1.10.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 11)) (1.13.1+cu116)\n",
      "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 12)) (0.14.1+cu116)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 13)) (4.65.0)\n",
      "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 14)) (3.19.6)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 17)) (2.11.2)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 21)) (1.4.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 22)) (0.12.2)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 34)) (7.9.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 35)) (5.9.4)\n",
      "Collecting thop\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r ./yolov7/requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r ./yolov7/requirements.txt (line 4)) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r ./yolov7/requirements.txt (line 4)) (23.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r ./yolov7/requirements.txt (line 4)) (5.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r ./yolov7/requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r ./yolov7/requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r ./yolov7/requirements.txt (line 4)) (4.39.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r ./yolov7/requirements.txt (line 4)) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r ./yolov7/requirements.txt (line 9)) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r ./yolov7/requirements.txt (line 9)) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r ./yolov7/requirements.txt (line 9)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r ./yolov7/requirements.txt (line 9)) (3.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r ./yolov7/requirements.txt (line 11)) (4.5.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (63.4.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (2.2.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (1.4.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (1.51.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (2.16.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r ./yolov7/requirements.txt (line 21)) (2022.7.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython->-r ./yolov7/requirements.txt (line 34)) (5.7.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython->-r ./yolov7/requirements.txt (line 34)) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython->-r ./yolov7/requirements.txt (line 34)) (0.7.5)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython->-r ./yolov7/requirements.txt (line 34)) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython->-r ./yolov7/requirements.txt (line 34)) (2.0.10)\n",
      "Collecting jedi>=0.10\n",
      "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m60.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from ipython->-r ./yolov7/requirements.txt (line 34)) (4.8.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython->-r ./yolov7/requirements.txt (line 34)) (2.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (1.3.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r ./yolov7/requirements.txt (line 4)) (3.15.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.10->ipython->-r ./yolov7/requirements.txt (line 34)) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (6.0.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r ./yolov7/requirements.txt (line 34)) (0.2.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (2.1.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->ipython->-r ./yolov7/requirements.txt (line 34)) (0.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r ./yolov7/requirements.txt (line 17)) (3.2.2)\n",
      "Installing collected packages: jedi, thop\n",
      "Successfully installed jedi-0.18.2 thop-0.1.1.post2209072238\n",
      "--2023-03-19 09:42:10--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ba7d01ee-125a-4134-8864-fa1abcbf94d5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230319%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230319T094210Z&X-Amz-Expires=300&X-Amz-Signature=80670ff6d7c182512edad3a3b76ca934e888653a1d25aacab9521d1680f5d579&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-tiny.pt&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-03-19 09:42:10--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ba7d01ee-125a-4134-8864-fa1abcbf94d5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230319%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230319T094210Z&X-Amz-Expires=300&X-Amz-Signature=80670ff6d7c182512edad3a3b76ca934e888653a1d25aacab9521d1680f5d579&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-tiny.pt&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12639769 (12M) [application/octet-stream]\n",
      "Saving to: ‚Äò/content/yolov7/yolov7-tiny.pt‚Äô\n",
      "\n",
      "yolov7-tiny.pt      100%[===================>]  12.05M  1.56MB/s    in 12s     \n",
      "\n",
      "2023-03-19 09:42:22 (1.04 MB/s) - ‚Äò/content/yolov7/yolov7-tiny.pt‚Äô saved [12639769/12639769]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/WongKinYiu/yolov7.git\n",
    "! pip install -r ./yolov7/requirements.txt\n",
    "# ! wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt \\\n",
    "#         -P /content/yolov7\n",
    "! wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt \\\n",
    "        -P /content/yolov7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDI36zfHJmpa"
   },
   "source": [
    "## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-KpZ6snIeQp"
   },
   "outputs": [],
   "source": [
    "# CFG_USE = '/content/yolov7/cfg/training/yolov7.yaml'\n",
    "CFG_USE = '/content/yolov7/cfg/training/yolov7-tiny.yaml'\n",
    "\n",
    "with open(CFG_USE, 'r') as f:\n",
    "    yolo_text = f.read()\n",
    "\n",
    "new_yolo_text = yolo_text.replace('nc: 80', f'nc: {len(CLASSES)}')\n",
    "with open(os.path.join(os.getcwd(), 'yolov7', 'cfg', 'training', 'cfg_yolov7_baggage.yaml'), 'w') as f:\n",
    "    f.write(new_yolo_text)\n",
    "\n",
    "config = {'train': train_path,\n",
    "          'val': val_path,\n",
    "          'test': test_path,\n",
    "          'nc': len(CLASSES),\n",
    "          'names': list(CLASSES)}\n",
    "\n",
    "with open(os.path.join(os.getcwd(), 'yolov7', 'data', 'data_baggage.yaml'), \"w\") as file:\n",
    "    yaml.dump(config, file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5Pw2rpYZ9n8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8c55eafc-8cb6-4ea1-8d4d-a2d87d6da460"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.14.0-py3-none-any.whl (2.0 MB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m69.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m184.3/184.3 KB\u001B[0m \u001B[31m19.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (63.4.3)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.17.0-py2.py3-none-any.whl (189 kB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m189.1/189.1 KB\u001B[0m \u001B[31m22.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m62.7/62.7 KB\u001B[0m \u001B[31m4.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=fab510b5895a370163e3f9dc711628b4c70e2f7907f65e343d344516bc3ac2e9\n",
      "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
      "Successfully built pathtools\n",
      "Installing collected packages: pathtools, appdirs, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.31 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.17.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.14.0\n",
      "W&B disabled.\n"
     ]
    }
   ],
   "source": [
    "! pip install wandb\n",
    "! wandb disabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df9l3txqZzvk"
   },
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ YOLOv7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6F822-Nuaaf7"
   },
   "source": [
    "## –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt \\\n",
    "-P /content/yolov7"
   ],
   "metadata": {
    "id": "gdH3yY-B8OWX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuDlUi6fIevq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1a8e33bc-849c-4c13-809f-e6ddc4a1495b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/yolov7\n"
     ]
    }
   ],
   "source": [
    "# –≠—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—ã—á–Ω–æ –Ω–µ –º–µ–Ω—è—é—Ç—Å—è\n",
    "BATCH_SIZE = 4\n",
    "WORKERS = 8\n",
    "# DATA = '/content/drive/MyDrive/Baggage/data_baggage.yaml'\n",
    "DATA = '/content/yolov7/data/data_baggage.yaml'\n",
    "\n",
    "# –° —ç—Ç–∏–º–∏ –ø–∞—Ä–º–µ—Ç—Ä–∞–º–∏ –ø–æ—ç–∫—Å–ø–µ—Ä–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å\n",
    "EPOCHS = 150\n",
    "# WEIGHTS = '/content/yolov7/yolov7.pt'\n",
    "# WEIGHTS = '/content/drive/MyDrive/Baggage/baggage_detection/Epochs:100_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False/weights/last.pt'\n",
    "WEIGHTS = '/content/yolov7/yolov7-tiny.pt'\n",
    "# WEIGHTS = '/content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY/EPOCH:133_CFG:cfg_yolov7_baggage.yaml_WEIGHTS:last.pt_HYP:hyp.scratch.custom.yaml_RESIZE:False_WITHOUT-END2END2/weights/last.pt'\n",
    "# HYP = '/content/yolov7/data/hyp.scratch.custom.yaml'\n",
    "# HYP = '/content/drive/MyDrive/Baggage/baggage_detection/epochs_50__cfg_yolov7.yaml__weights_yolov7.pt__hyp_hyp.scratch.custom.yaml__resize_False/hyp.yaml'\n",
    "# HYP = '/content/yolov7/data/hyp.scratch.tiny.yaml'\n",
    "HYP = '/content/yolov7/data/hyp.scratch.custom.yaml'\n",
    "\n",
    "# CFG = '/content/drive/MyDrive/Baggage/cfg_yolov7_baggage.yaml'\n",
    "CFG = '/content/yolov7/cfg/training/cfg_yolov7_baggage.yaml'\n",
    "\n",
    "# –ò–º–µ–Ω–∞ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞\n",
    "# PROJECT = \"/content/drive/MyDrive/Baggage/baggage_detection\"\n",
    "PROJECT = \"/content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY\"\n",
    "if RESIZE_IMAGES:\n",
    "\n",
    "    # –≠—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –º–µ–Ω—è—é—Ç—Å—è —Ä–µ–¥–∫–æ\n",
    "    IMG_SIZE = RESIZE_IMAGES\n",
    "\n",
    "else:\n",
    "\n",
    "    # –≠—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –º–µ–Ω—è—é—Ç—Å—è —Ä–µ–¥–∫–æ\n",
    "    IMG_SIZE = 640\n",
    "\n",
    "RUN_NAME = f\"EPOCH:{EPOCHS}_CFG:{CFG.split('/')[-1]}_WEIGHTS:{WEIGHTS.split('/')[-1]}_HYP:{HYP.split('/')[-1]}_RESIZE:{RESIZE_IMAGES}_WITHOUT-END2END\"\n",
    "\n",
    "% cd yolov7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7REjvMbCby4M"
   },
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# TINY\n",
    "\n",
    "# –ú–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º --multi-scale –¥–ª—è —Å—Ç–∞—Ç–∏—á–Ω–æ–≥–æ –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ \n",
    "# —Ä–∞–∑–º–µ—Ä–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–µ—Å–ª–∏ RESIZE_IMAGES == False, —Ç–æ –≤—Å—Ç–∞–≤–∏—Ç—å --multi-scale,\n",
    "# –µ—Å–ª–∏  RESIZE_IMAGES != False, —Ç–æ —É–±—Ä–∞—Ç—å --multi-scale)\n",
    "! wandb disabled\n",
    "\n",
    "!python /content/yolov7/train.py --workers {WORKERS} --device 0 --img-size {IMG_SIZE}\\\n",
    "--batch-size {BATCH_SIZE} --epoch {EPOCHS} --data {DATA} \\\n",
    "--cfg {CFG} --weights {WEIGHTS} \\\n",
    "--hyp {HYP} --name {RUN_NAME} --project {PROJECT} \\\n",
    "--multi-scale \n",
    "# --cache-images"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvPLB-zfX7Mm",
    "outputId": "610d7b57-0edb-4f58-c99c-2b9781618d9e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "W&B disabled.\n",
      "YOLOR üöÄ v0.1-122-g3b41c2c torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
      "\n",
      "Namespace(weights='/content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY/EPOCH:133_CFG:cfg_yolov7_baggage.yaml_WEIGHTS:last.pt_HYP:hyp.scratch.custom.yaml_RESIZE:False_WITHOUT-END2END2/weights/last.pt', cfg='/content/yolov7/cfg/training/cfg_yolov7_baggage.yaml', data='/content/yolov7/data/data_baggage.yaml', hyp='/content/yolov7/data/hyp.scratch.custom.yaml', epochs=17, batch_size=4, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=True, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='/content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY', entity=None, name='EPOCH:17_CFG:cfg_yolov7_baggage.yaml_WEIGHTS:last.pt_HYP:hyp.scratch.custom.yaml_RESIZE:False_WITHOUT-END2END', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='/content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY/EPOCH:17_CFG:cfg_yolov7_baggage.yaml_WEIGHTS:last.pt_HYP:hyp.scratch.custom.yaml_RESIZE:False_WITHOUT-END2END', total_batch_size=4)\n",
      "\u001B[34m\u001B[1mtensorboard: \u001B[0mStart with 'tensorboard --logdir /content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY', view at http://localhost:6006/\n",
      "2023-03-14 13:47:17.942009: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-14 13:47:21.284152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
      "2023-03-14 13:47:21.284352: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
      "2023-03-14 13:47:21.284381: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
      "config set opt = {'weights': '/content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY/EPOCH:133_CFG:cfg_yolov7_baggage.yaml_WEIGHTS:last.pt_HYP:hyp.scratch.custom.yaml_RESIZE:False_WITHOUT-END2END2/weights/last.pt', 'cfg': '/content/yolov7/cfg/training/cfg_yolov7_baggage.yaml', 'data': '/content/yolov7/data/data_baggage.yaml', 'hyp': {'lr0': 0.01, 'lrf': 0.1, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.3, 'cls_pw': 1.0, 'obj': 0.7, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.2, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0, 'paste_in': 0.0, 'loss_ota': 1}, 'epochs': 17, 'batch_size': 4, 'img_size': [640, 640], 'rect': False, 'resume': False, 'nosave': False, 'notest': False, 'noautoanchor': False, 'evolve': False, 'bucket': '', 'cache_images': False, 'image_weights': False, 'device': '0', 'multi_scale': True, 'single_cls': False, 'adam': False, 'sync_bn': False, 'local_rank': -1, 'workers': 8, 'project': '/content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY', 'entity': None, 'name': 'EPOCH:17_CFG:cfg_yolov7_baggage.yaml_WEIGHTS:last.pt_HYP:hyp.scratch.custom.yaml_RESIZE:False_WITHOUT-END2END', 'exist_ok': False, 'quad': False, 'linear_lr': False, 'label_smoothing': 0.0, 'upload_dataset': False, 'bbox_interval': -1, 'save_period': -1, 'artifact_alias': 'latest', 'freeze': [0], 'v5_metric': False, 'world_size': 1, 'global_rank': -1, 'save_dir': '/content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY/EPOCH:17_CFG:cfg_yolov7_baggage.yaml_WEIGHTS:last.pt_HYP:hyp.scratch.custom.yaml_RESIZE:False_WITHOUT-END2END', 'total_batch_size': 4} - None\n",
      "config set data_dict = {'names': ['Gun', 'Knife', 'Wrench', 'Pliers', 'Scissors'], 'nc': 5, 'test': '/content/yolov7_dataset/test', 'train': '/content/yolov7_dataset/train', 'val': '/content/yolov7_dataset/val'} - None\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      "  2                -1  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      "  3                -2  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      "  4                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      "  5                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      "  6  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
      "  7                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      "  8                -1  1         0  models.common.MP                        []                            \n",
      "  9                -1  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 10                -2  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 11                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 12                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 13  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 15                -1  1         0  models.common.MP                        []                            \n",
      " 16                -1  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 17                -2  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 20  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 22                -1  1         0  models.common.MP                        []                            \n",
      " 23                -1  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 24                -2  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 27  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
      " 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 29                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 30                -2  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 31                -1  1         0  models.common.SP                        [5]                           \n",
      " 32                -2  1         0  models.common.SP                        [9]                           \n",
      " 33                -3  1         0  models.common.SP                        [13]                          \n",
      " 34  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
      " 35                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 36          [-1, -7]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 38                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 39                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 40                21  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 41          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 42                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 43                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 44                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 45                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 46  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
      " 47                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 48                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 50                14  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 51          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 52                -1  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 53                -2  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 54                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 55                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 56  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
      " 57                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 58                -1  1     73984  models.common.Conv                      [64, 128, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 59          [-1, 47]  1         0  models.common.Concat                    [1]                           \n",
      " 60                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 61                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 62                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 63                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 64  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
      " 65                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 66                -1  1    295424  models.common.Conv                      [128, 256, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 67          [-1, 37]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 69                -2  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 70                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 71                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 72  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
      " 73                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 74                57  1     73984  models.common.Conv                      [64, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 75                65  1    295424  models.common.Conv                      [128, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 76                73  1   1180672  models.common.Conv                      [256, 512, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
      " 77      [74, 75, 76]  1     27956  models.yolo.IDetect                     [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 263 layers, 6025812 parameters, 6025812 gradients, 13.2 GFLOPS\n",
      "\n",
      "Transferred 342/344 items from /content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY/EPOCH:133_CFG:cfg_yolov7_baggage.yaml_WEIGHTS:last.pt_HYP:hyp.scratch.custom.yaml_RESIZE:False_WITHOUT-END2END2/weights/last.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 58 .bias, 58 conv.weight, 61 other\n",
      "/content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY/EPOCH:133_CFG:cfg_yolov7_baggage.yaml_WEIGHTS:last.pt_HYP:hyp.scratch.custom.yaml_RESIZE:False_WITHOUT-END2END2/weights/last.pt has been trained for 33 epochs. Fine-tuning for 17 additional epochs.\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning '/content/yolov7_dataset/train/labels' images and labels... 6214 found, 0 missing, 1144 empty, 0 corrupted: 100% 6214/6214 [00:01<00:00, 3783.72it/s]\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: /content/yolov7_dataset/train/labels.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/content/yolov7_dataset/val/labels' images and labels... 2072 found, 0 missing, 377 empty, 0 corrupted: 100% 2072/2072 [00:01<00:00, 1718.83it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: /content/yolov7_dataset/val/labels.cache\n",
      "\n",
      "\u001B[34m\u001B[1mautoanchor: \u001B[0mAnalyzing anchors... anchors/target = 4.69, Best Possible Recall (BPR) = 1.0000\n",
      "Image sizes 640 train, 640 test\n",
      "Using 2 dataloader workers\n",
      "Logging results to /content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY/EPOCH:17_CFG:cfg_yolov7_baggage.yaml_WEIGHTS:last.pt_HYP:hyp.scratch.custom.yaml_RESIZE:False_WITHOUT-END2END\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     34/49     5.06G   0.03023  0.006429  0.002964   0.03963         8       960: 100% 1554/1554 [06:59<00:00,  3.71it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:56<00:00,  4.61it/s]\n",
      "                 all        2072        3263       0.852       0.723       0.794       0.486\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     35/49     0.47G   0.03243  0.006576  0.003702   0.04271         2       352: 100% 1554/1554 [06:05<00:00,  4.25it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:36<00:00,  7.02it/s]\n",
      "                 all        2072        3263       0.837       0.692       0.774       0.455\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     36/49    0.487G   0.03314  0.006996  0.003821   0.04396         0       800: 100% 1554/1554 [06:07<00:00,  4.23it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:34<00:00,  7.46it/s]\n",
      "                 all        2072        3263       0.795       0.705        0.76       0.448\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     37/49    0.512G   0.03325  0.007054  0.003999    0.0443         8       640: 100% 1554/1554 [06:09<00:00,  4.21it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:35<00:00,  7.40it/s]\n",
      "                 all        2072        3263        0.82       0.704       0.772       0.459\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     38/49    0.497G   0.03281  0.006709  0.003745   0.04326         2       832: 100% 1554/1554 [06:06<00:00,  4.24it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:34<00:00,  7.42it/s]\n",
      "                 all        2072        3263       0.792       0.715       0.768       0.457\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     39/49    0.495G   0.03266   0.00707  0.003729   0.04346         3       608: 100% 1554/1554 [06:04<00:00,  4.27it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:34<00:00,  7.45it/s]\n",
      "                 all        2072        3263       0.811       0.698       0.762       0.445\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     40/49    0.535G   0.03267  0.006774  0.003654    0.0431         2       544: 100% 1554/1554 [05:57<00:00,  4.35it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:34<00:00,  7.52it/s]\n",
      "                 all        2072        3263        0.78       0.721       0.761       0.457\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     41/49    0.493G   0.03196   0.00673  0.003546   0.04223         4       672: 100% 1554/1554 [06:09<00:00,  4.21it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:34<00:00,  7.47it/s]\n",
      "                 all        2072        3263       0.814       0.725       0.784       0.456\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     42/49      1.5G    0.0317  0.006594  0.003373   0.04167         3       352: 100% 1554/1554 [06:06<00:00,  4.24it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:35<00:00,  7.26it/s]\n",
      "                 all        2072        3263       0.825       0.731       0.787       0.474\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     43/49    0.503G   0.03088   0.00652  0.002925   0.04033         2       384: 100% 1554/1554 [06:04<00:00,  4.26it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:35<00:00,  7.30it/s]\n",
      "                 all        2072        3263       0.809       0.742       0.786       0.476\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     44/49     1.67G   0.03114  0.006612  0.002958   0.04071        16       544: 100% 1554/1554 [06:04<00:00,  4.27it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:37<00:00,  6.93it/s]\n",
      "                 all        2072        3263       0.838       0.707       0.786        0.48\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     45/49     0.52G   0.02995  0.006351  0.002721   0.03902         5       736: 100% 1554/1554 [06:06<00:00,  4.24it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:34<00:00,  7.44it/s]\n",
      "                 all        2072        3263       0.819       0.743       0.798       0.489\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     46/49    0.533G   0.02993  0.006654   0.00276   0.03934         4       416: 100% 1554/1554 [06:08<00:00,  4.22it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:33<00:00,  7.63it/s]\n",
      "                 all        2072        3263       0.831        0.74       0.802       0.492\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     47/49     1.58G   0.02921  0.006425  0.002681   0.03832         9       352: 100% 1554/1554 [06:07<00:00,  4.23it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:38<00:00,  6.76it/s]\n",
      "                 all        2072        3263       0.854       0.733       0.805       0.502\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     48/49     1.63G   0.02909  0.006256   0.00265   0.03799         1       960: 100% 1554/1554 [06:10<00:00,  4.20it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:36<00:00,  7.01it/s]\n",
      "                 all        2072        3263       0.872       0.712       0.802       0.504\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     49/49    0.549G   0.02886  0.006288  0.002379   0.03753         0       896: 100% 1554/1554 [06:10<00:00,  4.20it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:38<00:00,  6.78it/s]\n",
      "                 all        2072        3263       0.834        0.75       0.806       0.502\n",
      "                 Gun        2072         877       0.959       0.957       0.984       0.673\n",
      "               Knife        2072         566       0.874       0.719       0.813       0.484\n",
      "              Wrench        2072         516       0.812        0.74       0.811       0.518\n",
      "              Pliers        2072         926       0.861        0.77       0.849       0.526\n",
      "            Scissors        2072         378       0.664       0.566       0.573       0.311\n",
      "16 epochs completed in 1.814 hours.\n",
      "\n",
      "Optimizer stripped from /content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY/EPOCH:17_CFG:cfg_yolov7_baggage.yaml_WEIGHTS:last.pt_HYP:hyp.scratch.custom.yaml_RESIZE:False_WITHOUT-END2END/weights/last.pt, 12.3MB\n",
      "Optimizer stripped from /content/drive/MyDrive/Baggage/baggage_detection/YOLOV7-TINY/EPOCH:17_CFG:cfg_yolov7_baggage.yaml_WEIGHTS:last.pt_HYP:hyp.scratch.custom.yaml_RESIZE:False_WITHOUT-END2END/weights/best.pt, 12.3MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# –ú–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º --multi-scale –¥–ª—è —Å—Ç–∞—Ç–∏—á–Ω–æ–≥–æ –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ \n",
    "# —Ä–∞–∑–º–µ—Ä–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–µ—Å–ª–∏ RESIZE_IMAGES == False, —Ç–æ –≤—Å—Ç–∞–≤–∏—Ç—å --multi-scale,\n",
    "# –µ—Å–ª–∏  RESIZE_IMAGES != False, —Ç–æ —É–±—Ä–∞—Ç—å --multi-scale)\n",
    "\n",
    "! python /content/yolov7/train.py --workers {WORKERS} --device 0 --img-size {IMG_SIZE}\\\n",
    "--batch-size {BATCH_SIZE} --epoch {EPOCHS} --data {DATA} \\\n",
    "--cfg /content/yolov7/cfg/training/yolov7_baggage.yaml --weights {WEIGHTS} \\\n",
    "--hyp {HYP} --name {RUN_NAME} --project {PROJECT} \\\n",
    "--multi-scale \n",
    "# --cache-images"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4VdlhbiMvCw",
    "outputId": "e6355e7b-4b6b-45c2-dbda-4cafe2469c6e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "YOLOR üöÄ v0.1-121-g2fdc7f1 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15109.875MB)\n",
      "\n",
      "Namespace(adam=False, artifact_alias='latest', batch_size=4, bbox_interval=-1, bucket='', cache_images=False, cfg='/content/yolov7/cfg/training/yolov7_baggage.yaml', data='/content/yolov7/data/data_baggage.yaml', device='0', entity=None, epochs=31, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='/content/drive/MyDrive/Baggage/baggage_detection/epochs_50__cfg_yolov7.yaml__weights_yolov7.pt__hyp_hyp.scratch.custom.yaml__resize_False/hyp.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=True, name='Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False', noautoanchor=False, nosave=False, notest=False, project='/content/drive/MyDrive/Baggage/baggage_detection', quad=False, rect=False, resume=False, save_dir='/content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=4, upload_dataset=False, v5_metric=False, weights='/content/drive/MyDrive/Baggage/baggage_detection/Epochs:100_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False/weights/last.pt', workers=8, world_size=1)\n",
      "\u001B[34m\u001B[1mtensorboard: \u001B[0mStart with 'tensorboard --logdir /content/drive/MyDrive/Baggage/baggage_detection', view at http://localhost:6006/\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
      "config set opt = {'weights': '/content/drive/MyDrive/Baggage/baggage_detection/Epochs:100_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False/weights/last.pt', 'cfg': '/content/yolov7/cfg/training/yolov7_baggage.yaml', 'data': '/content/yolov7/data/data_baggage.yaml', 'hyp': {'lr0': 0.01, 'lrf': 0.1, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.3, 'cls_pw': 1.0, 'obj': 0.7, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.2, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0, 'paste_in': 0.0, 'loss_ota': 1}, 'epochs': 31, 'batch_size': 4, 'img_size': [640, 640], 'rect': False, 'resume': False, 'nosave': False, 'notest': False, 'noautoanchor': False, 'evolve': False, 'bucket': '', 'cache_images': False, 'image_weights': False, 'device': '0', 'multi_scale': True, 'single_cls': False, 'adam': False, 'sync_bn': False, 'local_rank': -1, 'workers': 8, 'project': '/content/drive/MyDrive/Baggage/baggage_detection', 'entity': None, 'name': 'Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False', 'exist_ok': False, 'quad': False, 'linear_lr': False, 'label_smoothing': 0.0, 'upload_dataset': False, 'bbox_interval': -1, 'save_period': -1, 'artifact_alias': 'latest', 'freeze': [0], 'v5_metric': False, 'world_size': 1, 'global_rank': -1, 'save_dir': '/content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False2', 'total_batch_size': 4} - None\n",
      "config set data_dict = {'names': ['Gun', 'Knife', 'Wrench', 'Pliers', 'Scissors', 'Hammer'], 'nc': 6, 'test': '/content/yolov7_dataset/test', 'train': '/content/yolov7_dataset/train', 'val': '/content/yolov7_dataset/val'} - None\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1     61126  models.yolo.IDetect                     [6, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 415 layers, 37223526 parameters, 37223526 gradients, 105.2 GFLOPS\n",
      "\n",
      "Transferred 564/566 items from /content/drive/MyDrive/Baggage/baggage_detection/Epochs:100_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False/weights/last.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning '/content/yolov7_dataset/train/labels' images and labels... 6214 found, 0 missing, 1144 empty, 0 corrupted: 100% 6214/6214 [00:02<00:00, 2165.82it/s]\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: /content/yolov7_dataset/train/labels.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/content/yolov7_dataset/val/labels' images and labels... 2072 found, 0 missing, 377 empty, 0 corrupted: 100% 2072/2072 [00:01<00:00, 1147.92it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: /content/yolov7_dataset/val/labels.cache\n",
      "\n",
      "\u001B[34m\u001B[1mautoanchor: \u001B[0mAnalyzing anchors... anchors/target = 4.96, Best Possible Recall (BPR) = 0.9998\n",
      "Image sizes 640 train, 640 test\n",
      "Using 2 dataloader workers\n",
      "Logging results to /content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False2\n",
      "Starting training for 31 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     20/30     3.89G   0.03275  0.006972  0.004214   0.04394         6       960: 100% 1554/1554 [11:31<00:00,  2.25it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [02:12<00:00,  1.96it/s]\n",
      "                 all        2072        3263       0.781       0.701       0.768        0.46\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     21/30     3.83G   0.03072  0.006593  0.003645   0.04095         4       352: 100% 1554/1554 [08:32<00:00,  3.03it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:44<00:00,  5.82it/s]\n",
      "                 all        2072        3263       0.808       0.717       0.788       0.489\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     22/30     3.84G    0.0295  0.006574  0.003046   0.03912         3       800: 100% 1554/1554 [08:34<00:00,  3.02it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:45<00:00,  5.69it/s]\n",
      "                 all        2072        3263       0.836       0.718       0.798       0.501\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     23/30     3.86G   0.02931  0.006478  0.003164   0.03895         5       640: 100% 1554/1554 [08:32<00:00,  3.03it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:42<00:00,  6.07it/s]\n",
      "                 all        2072        3263       0.789       0.753       0.796         0.5\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     24/30     3.88G   0.02895  0.006147     0.003    0.0381         3       832: 100% 1554/1554 [08:42<00:00,  2.98it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:44<00:00,  5.84it/s]\n",
      "                 all        2072        3263       0.845       0.722       0.804       0.509\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     25/30     3.84G   0.02897  0.006617  0.003087   0.03868         1       608: 100% 1554/1554 [08:35<00:00,  3.01it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:43<00:00,  5.93it/s]\n",
      "                 all        2072        3263       0.806       0.746       0.802        0.51\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     26/30     3.83G   0.02843  0.006449  0.002853   0.03773         4       544: 100% 1554/1554 [08:28<00:00,  3.05it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:44<00:00,  5.78it/s]\n",
      "                 all        2072        3263        0.81       0.756        0.81       0.518\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     27/30     3.82G   0.02767  0.006312   0.00263   0.03661        11       672: 100% 1554/1554 [08:30<00:00,  3.04it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:43<00:00,  5.93it/s]\n",
      "                 all        2072        3263       0.846       0.737       0.816       0.521\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     28/30     6.87G   0.02796  0.006342  0.002476   0.03678         4       352: 100% 1554/1554 [08:24<00:00,  3.08it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:43<00:00,  5.98it/s]\n",
      "                 all        2072        3263       0.817       0.768       0.818       0.528\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     29/30     3.91G   0.02715  0.006201  0.002277   0.03563        10       384: 100% 1554/1554 [08:33<00:00,  3.03it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:44<00:00,  5.88it/s]\n",
      "                 all        2072        3263       0.826       0.754       0.816       0.527\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     30/30     6.71G   0.02746    0.0063  0.002305   0.03607         2       544: 100% 1554/1554 [08:17<00:00,  3.12it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 259/259 [00:46<00:00,  5.58it/s]\n",
      "                 all        2072        3263       0.855       0.751       0.824       0.533\n",
      "                 Gun        2072         877       0.968       0.951       0.987         0.7\n",
      "               Knife        2072         566       0.928       0.711       0.842       0.522\n",
      "              Wrench        2072         516       0.829       0.795       0.853       0.584\n",
      "              Pliers        2072         926       0.876       0.807       0.879        0.57\n",
      "            Scissors        2072         378       0.673       0.489        0.56       0.287\n",
      "11 epochs completed in 1.784 hours.\n",
      "\n",
      "Optimizer stripped from /content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False2/weights/last.pt, 74.8MB\n",
      "Optimizer stripped from /content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False2/weights/best.pt, 74.8MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç ONNX"
   ],
   "metadata": {
    "id": "fMBIjOxaTqaO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### –†–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏—è (yolov7)\n"
   ],
   "metadata": {
    "id": "DGxqb5gQt0C3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%cd yolov7\n",
    "\n",
    "# import\n",
    "from copy import deepcopy\n",
    "from models.yolo import Model\n",
    "import torch\n",
    "from utils.torch_utils import select_device, is_parallel\n",
    "import yaml\n",
    "\n",
    "device = select_device('0', batch_size=1)\n",
    "# model trained by cfg/training/*.yaml\n",
    "ckpt = torch.load(\n",
    "    '/content/drive/MyDrive/Baggage/baggage_detection/epochs_50__cfg_yolov7.yaml__weights_yolov7.pt__hyp_hyp.scratch.custom.yaml__resize_False/weights/best.pt', \n",
    "    map_location=device)\n",
    "# reparameterized model in cfg/deploy/*.yaml\n",
    "nc = 6\n",
    "model = Model('cfg/deploy/yolov7.yaml', ch=3, nc=nc).to(device)\n",
    "# ch = self.yaml['ch'] = self.yaml.get('ch', ch)  # input channels\n",
    "\n",
    "with open('cfg/deploy/yolov7.yaml') as f:\n",
    "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "anchors = len(yml['anchors'][0]) // 2\n",
    "\n",
    "# copy intersect weights\n",
    "state_dict = ckpt['model'].float().state_dict()\n",
    "exclude = []\n",
    "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
    "model.load_state_dict(intersect_state_dict, strict=False)\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "\n",
    "# reparametrized YOLOR\n",
    "# print(model.nc, anchors, (model.nc+5)*anchors)\n",
    "# print(model.state_dict())\n",
    "# print(model)\n",
    "for i in range((nc+5)*3):\n",
    "    model.state_dict()['model.105.m.0.weight'].data[i, :, :, :] *= state_dict['model.105.im.0.implicit'].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.105.m.1.weight'].data[i, :, :, :] *= state_dict['model.105.im.1.implicit'].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.105.m.2.weight'].data[i, :, :, :] *= state_dict['model.105.im.2.implicit'].data[:, i, : :].squeeze()\n",
    "model.state_dict()['model.105.m.0.bias'].data += state_dict['model.105.m.0.weight'].mul(state_dict['model.105.ia.0.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.105.m.1.bias'].data += state_dict['model.105.m.1.weight'].mul(state_dict['model.105.ia.1.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.105.m.2.bias'].data += state_dict['model.105.m.2.weight'].mul(state_dict['model.105.ia.2.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.105.m.0.bias'].data *= state_dict['model.105.im.0.implicit'].data.squeeze()\n",
    "model.state_dict()['model.105.m.1.bias'].data *= state_dict['model.105.im.1.implicit'].data.squeeze()\n",
    "model.state_dict()['model.105.m.2.bias'].data *= state_dict['model.105.im.2.implicit'].data.squeeze()\n",
    "\n",
    "# model to be saved\n",
    "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
    "        'optimizer': None,\n",
    "        'training_results': None,\n",
    "        'epoch': -1}\n",
    "\n",
    "# save reparameterized model\n",
    "# torch.save(ckpt, '/content/yolov7_u5/yolov7_baggage_reparam.pt')\n",
    "torch.save(ckpt, '/content/yolov7/yolov7_baggage_reparam.pt')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WOidxK-TpbU",
    "outputId": "c3bb2db4-3806-44ba-b928-320b49b41117"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/yolov7\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### –†–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏—è (yolov7-tiny)"
   ],
   "metadata": {
    "id": "SmXix5jF0LjR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_path = '/content/yolov7/best.pt'\n",
    "%cd yolov7\n",
    "\n",
    "# import\n",
    "from copy import deepcopy\n",
    "from models.yolo import Model\n",
    "import torch\n",
    "from utils.torch_utils import select_device, is_parallel\n",
    "import yaml\n",
    "\n",
    "device = select_device('0', batch_size=1)\n",
    "# model trained by cfg/training/*.yaml\n",
    "ckpt = torch.load(model_path, map_location=device)\n",
    "# ckpt = torch.load('cfg/training/yolov7_training.pt', map_location=device)\n",
    "# reparameterized model in cfg/deploy/*.yaml\n",
    "nc_baggage = 5\n",
    "# model = Model('cfg/deploy/yolov7.yaml', ch=3, nc=nc).to(device)\n",
    "# model = Model('/content/drive/MyDrive/Baggage/cfg_yolov7_baggage.yaml', ch=3, nc=nc).to(device)\n",
    "model = Model('/content/yolov7/cfg/training/cfg_yolov7_baggage.yaml', ch=3, nc=nc_baggage).to(device)\n",
    "\n",
    "# with open('cfg/deploy/yolov7.yaml') as f:\n",
    "with open('/content/yolov7/cfg/training/cfg_yolov7_baggage.yaml') as f:\n",
    "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "anchors = len(yml['anchors'][0]) // 2\n",
    "\n",
    "# copy intersect weights\n",
    "state_dict = ckpt['model'].float().state_dict()\n",
    "exclude = []\n",
    "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
    "model.load_state_dict(intersect_state_dict, strict=False)\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "\n",
    "# reparametrized YOLOR\n",
    "# –∑–∞–º–µ–Ω—è–µ–º .105. –Ω–∞ .77.\n",
    "for i in range((nc_baggage+5)*anchors):\n",
    "    model.state_dict()['model.77.m.0.weight'].data[i, :, :, :] *= state_dict['model.77.im.0.implicit'].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.77.m.1.weight'].data[i, :, :, :] *= state_dict['model.77.im.1.implicit'].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.77.m.2.weight'].data[i, :, :, :] *= state_dict['model.77.im.2.implicit'].data[:, i, : :].squeeze()\n",
    "model.state_dict()['model.77.m.0.bias'].data += state_dict['model.77.m.0.weight'].mul(state_dict['model.77.ia.0.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.77.m.1.bias'].data += state_dict['model.77.m.1.weight'].mul(state_dict['model.77.ia.1.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.77.m.2.bias'].data += state_dict['model.77.m.2.weight'].mul(state_dict['model.77.ia.2.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.77.m.0.bias'].data *= state_dict['model.77.im.0.implicit'].data.squeeze()\n",
    "model.state_dict()['model.77.m.1.bias'].data *= state_dict['model.77.im.1.implicit'].data.squeeze()\n",
    "model.state_dict()['model.77.m.2.bias'].data *= state_dict['model.77.im.2.implicit'].data.squeeze()\n",
    "\n",
    "# model to be saved\n",
    "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
    "        'optimizer': None,\n",
    "        'training_results': None,\n",
    "        'epoch': -1}\n",
    "\n",
    "# save reparameterized model\n",
    "# torch.save(ckpt, 'cfg/deploy/yolov7.pt')\n",
    "torch.save(ckpt, '/content/yolov7/yolov7-tiny_baggage_reparam.pt')"
   ],
   "metadata": {
    "id": "PJuPLj2Z0K6c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ff5f1a43-c80e-4241-9da1-e320b983f77d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/yolov7\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ yolov7 (—Ä–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–π) –≤ ONNX —Ñ–æ—Ä–º–∞—Ç"
   ],
   "metadata": {
    "id": "So28J1n62iqD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install onnx \n",
    "# !pip install onnxruntime\n",
    "\n",
    "!pip install coremltools onnx onnx-simplifier onnxruntime-gpu openvino-dev tensorflow # GPU\n",
    "# !pip install coremltools onnx onnx-simplifier onnxruntime openvino-dev tensorflow-cpu # CPU\n",
    "%cd yolov7\n",
    "\n",
    "CONF = 0.6\n",
    "IOU = 0.65\n",
    "!python /content/yolov7/export.py \\\n",
    "--weights /content/yolov7/yolov7_baggage_reparam.pt \\\n",
    "--grid --end2end --simplify \\\n",
    "--topk-all 100 --iou-thres {CONF} --conf-thres {IOU} \\\n",
    "--img-size 640 640 --max-wh 640 # For onnxruntime, you need to specify this value as an integer, when it is 0 it means agnostic NMS, \n",
    "              # otherwise it is non-agnostic NMS"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eaqEMc6naAD",
    "outputId": "79927e07-0abe-4a60-a5b7-cbe820c954b8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Errno 2] No such file or directory: 'yolov7'\n",
      "/content/yolov7\n",
      "Import onnx_graphsurgeon failure: No module named 'onnx_graphsurgeon'\n",
      "Namespace(batch_size=1, conf_thres=0.65, device='cpu', dynamic=False, dynamic_batch=False, end2end=True, fp16=False, grid=True, img_size=[640, 640], include_nms=False, int8=False, iou_thres=0.6, max_wh=640, simplify=True, topk_all=100, weights='/content/yolov7/yolov7_baggage_reparam.pt')\n",
      "YOLOR üöÄ v0.1-121-g2fdc7f1 torch 1.13.1+cu116 CPU\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 306 layers, 36506851 parameters, 36506851 gradients, 103.2 GFLOPS\n",
      "\n",
      "Starting TorchScript export with torch 1.13.1+cu116...\n",
      "/content/yolov7/models/yolo.py:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
      "TorchScript export success, saved as /content/yolov7/yolov7_baggage_reparam.torchscript.pt\n",
      "Torch version 1.13.1+cu116 has not been tested with coremltools. You may run into unexpected errors. Torch 1.12.1 is the most recent version that has been tested.\n",
      "\n",
      "Starting CoreML export with coremltools 6.1...\n",
      "Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting graph.\n",
      "Adding op 'model.0.conv.bias' of type const\n",
      "Adding op 'model.0.conv.weight' of type const\n",
      "Adding op 'model.1.conv.bias' of type const\n",
      "Adding op 'model.1.conv.weight' of type const\n",
      "Adding op 'model.2.conv.bias' of type const\n",
      "Adding op 'model.2.conv.weight' of type const\n",
      "Adding op 'model.3.conv.bias' of type const\n",
      "Adding op 'model.3.conv.weight' of type const\n",
      "Adding op 'model.4.conv.bias' of type const\n",
      "Adding op 'model.4.conv.weight' of type const\n",
      "Adding op 'model.5.conv.bias' of type const\n",
      "Adding op 'model.5.conv.weight' of type const\n",
      "Adding op 'model.6.conv.bias' of type const\n",
      "Adding op 'model.6.conv.weight' of type const\n",
      "Adding op 'model.7.conv.bias' of type const\n",
      "Adding op 'model.7.conv.weight' of type const\n",
      "Adding op 'model.8.conv.bias' of type const\n",
      "Adding op 'model.8.conv.weight' of type const\n",
      "Adding op 'model.9.conv.bias' of type const\n",
      "Adding op 'model.9.conv.weight' of type const\n",
      "Adding op 'model.11.conv.bias' of type const\n",
      "Adding op 'model.11.conv.weight' of type const\n",
      "Adding op 'model.13.conv.bias' of type const\n",
      "Adding op 'model.13.conv.weight' of type const\n",
      "Adding op 'model.14.conv.bias' of type const\n",
      "Adding op 'model.14.conv.weight' of type const\n",
      "Adding op 'model.15.conv.bias' of type const\n",
      "Adding op 'model.15.conv.weight' of type const\n",
      "Adding op 'model.17.conv.bias' of type const\n",
      "Adding op 'model.17.conv.weight' of type const\n",
      "Adding op 'model.18.conv.bias' of type const\n",
      "Adding op 'model.18.conv.weight' of type const\n",
      "Adding op 'model.19.conv.bias' of type const\n",
      "Adding op 'model.19.conv.weight' of type const\n",
      "Adding op 'model.20.conv.bias' of type const\n",
      "Adding op 'model.20.conv.weight' of type const\n",
      "Adding op 'model.21.conv.bias' of type const\n",
      "Adding op 'model.21.conv.weight' of type const\n",
      "Adding op 'model.22.conv.bias' of type const\n",
      "Adding op 'model.22.conv.weight' of type const\n",
      "Adding op 'model.24.conv.bias' of type const\n",
      "Adding op 'model.24.conv.weight' of type const\n",
      "Adding op 'model.26.conv.bias' of type const\n",
      "Adding op 'model.26.conv.weight' of type const\n",
      "Adding op 'model.27.conv.bias' of type const\n",
      "Adding op 'model.27.conv.weight' of type const\n",
      "Adding op 'model.28.conv.bias' of type const\n",
      "Adding op 'model.28.conv.weight' of type const\n",
      "Adding op 'model.30.conv.bias' of type const\n",
      "Adding op 'model.30.conv.weight' of type const\n",
      "Adding op 'model.31.conv.bias' of type const\n",
      "Adding op 'model.31.conv.weight' of type const\n",
      "Adding op 'model.32.conv.bias' of type const\n",
      "Adding op 'model.32.conv.weight' of type const\n",
      "Adding op 'model.33.conv.bias' of type const\n",
      "Adding op 'model.33.conv.weight' of type const\n",
      "Adding op 'model.34.conv.bias' of type const\n",
      "Adding op 'model.34.conv.weight' of type const\n",
      "Adding op 'model.35.conv.bias' of type const\n",
      "Adding op 'model.35.conv.weight' of type const\n",
      "Adding op 'model.37.conv.bias' of type const\n",
      "Adding op 'model.37.conv.weight' of type const\n",
      "Adding op 'model.39.conv.bias' of type const\n",
      "Adding op 'model.39.conv.weight' of type const\n",
      "Adding op 'model.40.conv.bias' of type const\n",
      "Adding op 'model.40.conv.weight' of type const\n",
      "Adding op 'model.41.conv.bias' of type const\n",
      "Adding op 'model.41.conv.weight' of type const\n",
      "Adding op 'model.43.conv.bias' of type const\n",
      "Adding op 'model.43.conv.weight' of type const\n",
      "Adding op 'model.44.conv.bias' of type const\n",
      "Adding op 'model.44.conv.weight' of type const\n",
      "Adding op 'model.45.conv.bias' of type const\n",
      "Adding op 'model.45.conv.weight' of type const\n",
      "Adding op 'model.46.conv.bias' of type const\n",
      "Adding op 'model.46.conv.weight' of type const\n",
      "Adding op 'model.47.conv.bias' of type const\n",
      "Adding op 'model.47.conv.weight' of type const\n",
      "Adding op 'model.48.conv.bias' of type const\n",
      "Adding op 'model.48.conv.weight' of type const\n",
      "Adding op 'model.50.conv.bias' of type const\n",
      "Adding op 'model.50.conv.weight' of type const\n",
      "Adding op 'model.51.cv1.conv.bias' of type const\n",
      "Adding op 'model.51.cv1.conv.weight' of type const\n",
      "Adding op 'model.51.cv3.conv.bias' of type const\n",
      "Adding op 'model.51.cv3.conv.weight' of type const\n",
      "Adding op 'model.51.cv4.conv.bias' of type const\n",
      "Adding op 'model.51.cv4.conv.weight' of type const\n",
      "Adding op 'model.51.cv5.conv.bias' of type const\n",
      "Adding op 'model.51.cv5.conv.weight' of type const\n",
      "Adding op 'model.51.cv6.conv.bias' of type const\n",
      "Adding op 'model.51.cv6.conv.weight' of type const\n",
      "Adding op 'model.51.cv2.conv.bias' of type const\n",
      "Adding op 'model.51.cv2.conv.weight' of type const\n",
      "Adding op 'model.51.cv7.conv.bias' of type const\n",
      "Adding op 'model.51.cv7.conv.weight' of type const\n",
      "Adding op 'model.52.conv.bias' of type const\n",
      "Adding op 'model.52.conv.weight' of type const\n",
      "Adding op 'model.54.conv.bias' of type const\n",
      "Adding op 'model.54.conv.weight' of type const\n",
      "Adding op 'model.56.conv.bias' of type const\n",
      "Adding op 'model.56.conv.weight' of type const\n",
      "Adding op 'model.57.conv.bias' of type const\n",
      "Adding op 'model.57.conv.weight' of type const\n",
      "Adding op 'model.58.conv.bias' of type const\n",
      "Adding op 'model.58.conv.weight' of type const\n",
      "Adding op 'model.59.conv.bias' of type const\n",
      "Adding op 'model.59.conv.weight' of type const\n",
      "Adding op 'model.60.conv.bias' of type const\n",
      "Adding op 'model.60.conv.weight' of type const\n",
      "Adding op 'model.61.conv.bias' of type const\n",
      "Adding op 'model.61.conv.weight' of type const\n",
      "Adding op 'model.63.conv.bias' of type const\n",
      "Adding op 'model.63.conv.weight' of type const\n",
      "Adding op 'model.64.conv.bias' of type const\n",
      "Adding op 'model.64.conv.weight' of type const\n",
      "Adding op 'model.66.conv.bias' of type const\n",
      "Adding op 'model.66.conv.weight' of type const\n",
      "Adding op 'model.68.conv.bias' of type const\n",
      "Adding op 'model.68.conv.weight' of type const\n",
      "Adding op 'model.69.conv.bias' of type const\n",
      "Adding op 'model.69.conv.weight' of type const\n",
      "Adding op 'model.70.conv.bias' of type const\n",
      "Adding op 'model.70.conv.weight' of type const\n",
      "Adding op 'model.71.conv.bias' of type const\n",
      "Adding op 'model.71.conv.weight' of type const\n",
      "Adding op 'model.72.conv.bias' of type const\n",
      "Adding op 'model.72.conv.weight' of type const\n",
      "Adding op 'model.73.conv.bias' of type const\n",
      "Adding op 'model.73.conv.weight' of type const\n",
      "Adding op 'model.75.conv.bias' of type const\n",
      "Adding op 'model.75.conv.weight' of type const\n",
      "Adding op 'model.77.conv.bias' of type const\n",
      "Adding op 'model.77.conv.weight' of type const\n",
      "Adding op 'model.78.conv.bias' of type const\n",
      "Adding op 'model.78.conv.weight' of type const\n",
      "Adding op 'model.79.conv.bias' of type const\n",
      "Adding op 'model.79.conv.weight' of type const\n",
      "Adding op 'model.81.conv.bias' of type const\n",
      "Adding op 'model.81.conv.weight' of type const\n",
      "Adding op 'model.82.conv.bias' of type const\n",
      "Adding op 'model.82.conv.weight' of type const\n",
      "Adding op 'model.83.conv.bias' of type const\n",
      "Adding op 'model.83.conv.weight' of type const\n",
      "Adding op 'model.84.conv.bias' of type const\n",
      "Adding op 'model.84.conv.weight' of type const\n",
      "Adding op 'model.85.conv.bias' of type const\n",
      "Adding op 'model.85.conv.weight' of type const\n",
      "Adding op 'model.86.conv.bias' of type const\n",
      "Adding op 'model.86.conv.weight' of type const\n",
      "Adding op 'model.88.conv.bias' of type const\n",
      "Adding op 'model.88.conv.weight' of type const\n",
      "Adding op 'model.90.conv.bias' of type const\n",
      "Adding op 'model.90.conv.weight' of type const\n",
      "Adding op 'model.91.conv.bias' of type const\n",
      "Adding op 'model.91.conv.weight' of type const\n",
      "Adding op 'model.92.conv.bias' of type const\n",
      "Adding op 'model.92.conv.weight' of type const\n",
      "Adding op 'model.94.conv.bias' of type const\n",
      "Adding op 'model.94.conv.weight' of type const\n",
      "Adding op 'model.95.conv.bias' of type const\n",
      "Adding op 'model.95.conv.weight' of type const\n",
      "Adding op 'model.96.conv.bias' of type const\n",
      "Adding op 'model.96.conv.weight' of type const\n",
      "Adding op 'model.97.conv.bias' of type const\n",
      "Adding op 'model.97.conv.weight' of type const\n",
      "Adding op 'model.98.conv.bias' of type const\n",
      "Adding op 'model.98.conv.weight' of type const\n",
      "Adding op 'model.99.conv.bias' of type const\n",
      "Adding op 'model.99.conv.weight' of type const\n",
      "Adding op 'model.101.conv.bias' of type const\n",
      "Adding op 'model.101.conv.weight' of type const\n",
      "Adding op 'model.102.rbr_reparam.bias' of type const\n",
      "Adding op 'model.102.rbr_reparam.weight' of type const\n",
      "Adding op 'model.103.rbr_reparam.bias' of type const\n",
      "Adding op 'model.103.rbr_reparam.weight' of type const\n",
      "Adding op 'model.104.rbr_reparam.bias' of type const\n",
      "Adding op 'model.104.rbr_reparam.weight' of type const\n",
      "Adding op 'model.105.anchor_grid' of type const\n",
      "CoreML export failure: Core ML only supports tensors with rank <= 5. Layer \"model.105.anchor_grid\", with type \"const\", outputs a rank 6 tensor.\n",
      "\n",
      "Starting TorchScript-Lite export with torch 1.13.1+cu116...\n",
      "/content/yolov7/models/yolo.py:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
      "TorchScript-Lite export success, saved as /content/yolov7/yolov7_baggage_reparam.torchscript.ptl\n",
      "\n",
      "Starting ONNX export with onnx 1.12.0...\n",
      "onnxruntime\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:675: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n",
      "  if param.grad is not None:\n",
      "/content/yolov7/models/experimental.py:108: FutureWarning: 'torch.onnx._patch_torch._graph_op' is deprecated in version 1.13 and will be removed in version 1.14. Please note 'g.op()' is to be removed from torch.Graph. Please open a GitHub issue if you need this functionality..\n",
      "  return g.op(\"NonMaxSuppression\", boxes, scores, max_output_boxes_per_class, iou_threshold, score_threshold)\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/symbolic_opset9.py:5408: UserWarning: Exporting aten::index operator of advanced indexing in opset 12 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n",
      "\n",
      "Starting to simplify ONNX...\n",
      "ONNX export success, saved as /content/yolov7/yolov7_baggage_reparam.onnx\n",
      "\n",
      "Export complete (36.86s). Visualize with https://github.com/lutzroeder/netron.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ yolov7-tiny (—Ä–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–π) –≤ ONNX —Ñ–æ—Ä–º–∞—Ç"
   ],
   "metadata": {
    "id": "u5VQ-RHx2snb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install onnx \n",
    "# !pip install onnxruntime\n",
    "\n",
    "# !pip install coremltools onnx onnx-simplifier onnxruntime-gpu openvino-dev tensorflow # GPU\n",
    "# !pip install coremltools onnx onnx-simplifier onnxruntime openvino-dev tensorflow-cpu # CPU\n",
    "# %cd yolov7\n",
    "\n",
    "CONF = 0.6\n",
    "IOU = 0.65\n",
    "!python /content/yolov7/export.py --device 0\\\n",
    "--weights /content/yolov7/yolov7-tiny_baggage_reparam.pt \\\n",
    "--grid --simplify \\\n",
    "--topk-all 100 --iou-thres {CONF} --conf-thres {IOU} \\\n",
    "--img-size 640 640 --max-wh 640 # For onnxruntime, you need to specify this value as an integer, when it is 0 it means agnostic NMS, \n",
    "              # otherwise it is non-agnostic NMS"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qiYw4QL62sKX",
    "outputId": "abdba56a-b7d3-4c2b-f630-2432da0ca477"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Import onnx_graphsurgeon failure: No module named 'onnx_graphsurgeon'\n",
      "Namespace(weights='/content/yolov7/yolov7-tiny_baggage_reparam.pt', img_size=[640, 640], batch_size=1, dynamic=False, dynamic_batch=False, grid=True, end2end=False, max_wh=640, topk_all=100, iou_thres=0.6, conf_thres=0.65, device='0', simplify=True, include_nms=False, fp16=False, int8=False)\n",
      "YOLOR üöÄ v0.1-122-g3b41c2c torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
      "\n",
      "Fusing layers... \n",
      "IDetect.fuse\n",
      "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 208 layers, 6018420 parameters, 6018420 gradients, 13.1 GFLOPS\n",
      "\n",
      "Starting TorchScript export with torch 1.13.1+cu116...\n",
      "/content/yolov7/models/yolo.py:150: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
      "TorchScript export success, saved as /content/yolov7/yolov7-tiny_baggage_reparam.torchscript.pt\n",
      "scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "XGBoost version 1.7.4 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n",
      "\n",
      "Starting CoreML export with coremltools 6.2...\n",
      "Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting graph.\n",
      "Adding op 'model.0.conv.bias' of type const\n",
      "Adding op 'model.0.conv.weight' of type const\n",
      "Adding op 'model.1.conv.bias' of type const\n",
      "Adding op 'model.1.conv.weight' of type const\n",
      "Adding op 'model.2.conv.bias' of type const\n",
      "Adding op 'model.2.conv.weight' of type const\n",
      "Adding op 'model.3.conv.bias' of type const\n",
      "Adding op 'model.3.conv.weight' of type const\n",
      "Adding op 'model.4.conv.bias' of type const\n",
      "Adding op 'model.4.conv.weight' of type const\n",
      "Adding op 'model.5.conv.bias' of type const\n",
      "Adding op 'model.5.conv.weight' of type const\n",
      "Adding op 'model.7.conv.bias' of type const\n",
      "Adding op 'model.7.conv.weight' of type const\n",
      "Adding op 'model.9.conv.bias' of type const\n",
      "Adding op 'model.9.conv.weight' of type const\n",
      "Adding op 'model.10.conv.bias' of type const\n",
      "Adding op 'model.10.conv.weight' of type const\n",
      "Adding op 'model.11.conv.bias' of type const\n",
      "Adding op 'model.11.conv.weight' of type const\n",
      "Adding op 'model.12.conv.bias' of type const\n",
      "Adding op 'model.12.conv.weight' of type const\n",
      "Adding op 'model.14.conv.bias' of type const\n",
      "Adding op 'model.14.conv.weight' of type const\n",
      "Adding op 'model.16.conv.bias' of type const\n",
      "Adding op 'model.16.conv.weight' of type const\n",
      "Adding op 'model.17.conv.bias' of type const\n",
      "Adding op 'model.17.conv.weight' of type const\n",
      "Adding op 'model.18.conv.bias' of type const\n",
      "Adding op 'model.18.conv.weight' of type const\n",
      "Adding op 'model.19.conv.bias' of type const\n",
      "Adding op 'model.19.conv.weight' of type const\n",
      "Adding op 'model.21.conv.bias' of type const\n",
      "Adding op 'model.21.conv.weight' of type const\n",
      "Adding op 'model.23.conv.bias' of type const\n",
      "Adding op 'model.23.conv.weight' of type const\n",
      "Adding op 'model.24.conv.bias' of type const\n",
      "Adding op 'model.24.conv.weight' of type const\n",
      "Adding op 'model.25.conv.bias' of type const\n",
      "Adding op 'model.25.conv.weight' of type const\n",
      "Adding op 'model.26.conv.bias' of type const\n",
      "Adding op 'model.26.conv.weight' of type const\n",
      "Adding op 'model.28.conv.bias' of type const\n",
      "Adding op 'model.28.conv.weight' of type const\n",
      "Adding op 'model.29.conv.bias' of type const\n",
      "Adding op 'model.29.conv.weight' of type const\n",
      "Adding op 'model.30.conv.bias' of type const\n",
      "Adding op 'model.30.conv.weight' of type const\n",
      "Adding op 'model.35.conv.bias' of type const\n",
      "Adding op 'model.35.conv.weight' of type const\n",
      "Adding op 'model.37.conv.bias' of type const\n",
      "Adding op 'model.37.conv.weight' of type const\n",
      "Adding op 'model.38.conv.bias' of type const\n",
      "Adding op 'model.38.conv.weight' of type const\n",
      "Adding op 'model.40.conv.bias' of type const\n",
      "Adding op 'model.40.conv.weight' of type const\n",
      "Adding op 'model.42.conv.bias' of type const\n",
      "Adding op 'model.42.conv.weight' of type const\n",
      "Adding op 'model.43.conv.bias' of type const\n",
      "Adding op 'model.43.conv.weight' of type const\n",
      "Adding op 'model.44.conv.bias' of type const\n",
      "Adding op 'model.44.conv.weight' of type const\n",
      "Adding op 'model.45.conv.bias' of type const\n",
      "Adding op 'model.45.conv.weight' of type const\n",
      "Adding op 'model.47.conv.bias' of type const\n",
      "Adding op 'model.47.conv.weight' of type const\n",
      "Adding op 'model.48.conv.bias' of type const\n",
      "Adding op 'model.48.conv.weight' of type const\n",
      "Adding op 'model.50.conv.bias' of type const\n",
      "Adding op 'model.50.conv.weight' of type const\n",
      "Adding op 'model.52.conv.bias' of type const\n",
      "Adding op 'model.52.conv.weight' of type const\n",
      "Adding op 'model.53.conv.bias' of type const\n",
      "Adding op 'model.53.conv.weight' of type const\n",
      "Adding op 'model.54.conv.bias' of type const\n",
      "Adding op 'model.54.conv.weight' of type const\n",
      "Adding op 'model.55.conv.bias' of type const\n",
      "Adding op 'model.55.conv.weight' of type const\n",
      "Adding op 'model.57.conv.bias' of type const\n",
      "Adding op 'model.57.conv.weight' of type const\n",
      "Adding op 'model.58.conv.bias' of type const\n",
      "Adding op 'model.58.conv.weight' of type const\n",
      "Adding op 'model.60.conv.bias' of type const\n",
      "Adding op 'model.60.conv.weight' of type const\n",
      "Adding op 'model.61.conv.bias' of type const\n",
      "Adding op 'model.61.conv.weight' of type const\n",
      "Adding op 'model.62.conv.bias' of type const\n",
      "Adding op 'model.62.conv.weight' of type const\n",
      "Adding op 'model.63.conv.bias' of type const\n",
      "Adding op 'model.63.conv.weight' of type const\n",
      "Adding op 'model.65.conv.bias' of type const\n",
      "Adding op 'model.65.conv.weight' of type const\n",
      "Adding op 'model.66.conv.bias' of type const\n",
      "Adding op 'model.66.conv.weight' of type const\n",
      "Adding op 'model.68.conv.bias' of type const\n",
      "Adding op 'model.68.conv.weight' of type const\n",
      "Adding op 'model.69.conv.bias' of type const\n",
      "Adding op 'model.69.conv.weight' of type const\n",
      "Adding op 'model.70.conv.bias' of type const\n",
      "Adding op 'model.70.conv.weight' of type const\n",
      "Adding op 'model.71.conv.bias' of type const\n",
      "Adding op 'model.71.conv.weight' of type const\n",
      "Adding op 'model.73.conv.bias' of type const\n",
      "Adding op 'model.73.conv.weight' of type const\n",
      "Adding op 'model.74.conv.bias' of type const\n",
      "Adding op 'model.74.conv.weight' of type const\n",
      "Adding op 'model.75.conv.bias' of type const\n",
      "Adding op 'model.75.conv.weight' of type const\n",
      "Adding op 'model.76.conv.bias' of type const\n",
      "Adding op 'model.76.conv.weight' of type const\n",
      "Adding op 'model.77.anchor_grid' of type const\n",
      "CoreML export failure: Core ML only supports tensors with rank <= 5. Layer \"model.77.anchor_grid\", with type \"const\", outputs a rank 6 tensor. \n",
      "\n",
      "Starting TorchScript-Lite export with torch 1.13.1+cu116...\n",
      "/content/yolov7/models/yolo.py:150: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
      "TorchScript-Lite export success, saved as /content/yolov7/yolov7-tiny_baggage_reparam.torchscript.ptl\n",
      "\n",
      "Starting ONNX export with onnx 1.13.1...\n",
      "/content/yolov7/models/yolo.py:583: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if augment:\n",
      "/content/yolov7/models/yolo.py:615: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if profile:\n",
      "/content/yolov7/models/yolo.py:630: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if profile:\n",
      "\n",
      "Starting to simplify ONNX...\n",
      "ONNX export success, saved as /content/yolov7/yolov7-tiny_baggage_reparam.onnx\n",
      "\n",
      "Export complete (20.72s). Visualize with https://github.com/lutzroeder/netron.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## –ú–µ—Ç—Ä–∏–∫–∏"
   ],
   "metadata": {
    "id": "TitmG5vsx0wP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%cd yolov7"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocq1fwQtxxXU",
    "outputId": "16317a93-8220-45d7-d47c-003fbf2668d9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/yolov7\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python /content/yolov7/test.py  \\\n",
    "--img 640 --batch {BATCH_SIZE} --conf 0.001 --iou 0.65 --device 0 \\\n",
    "--weights /content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False2/weights/best.pt \\\n",
    "--name yolov7_baggage_testing --data {DATA} \\\n",
    "--project {PROJECT}/{RUN_NAME} \\\n",
    "--task test"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7cSEGGtxxhK",
    "outputId": "36b03460-18a7-42d9-b9dc-77435c9a8230"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(augment=False, batch_size=4, conf_thres=0.001, data='/content/yolov7/data/data_baggage.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='yolov7_baggage_testing', no_trace=False, project='/content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='test', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False2/weights/best.pt'])\n",
      "YOLOR üöÄ v0.1-121-g2fdc7f1 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15109.875MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 314 layers, 36508742 parameters, 6194944 gradients, 103.2 GFLOPS\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mScanning '/content/yolov7_dataset/test/labels' images and labels... 3552 found, 0 missing, 626 empty, 0 corrupted: 100% 3552/3552 [00:00<00:00, 4010.13it/s]\n",
      "\u001B[34m\u001B[1mtest: \u001B[0mNew cache created: /content/yolov7_dataset/test/labels.cache\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 888/888 [01:20<00:00, 11.03it/s]\n",
      "                 all        3552        5526       0.831       0.769       0.826       0.535\n",
      "                 Gun        3552        1485       0.961       0.952       0.982       0.692\n",
      "               Knife        3552         871       0.867       0.752       0.839       0.514\n",
      "              Wrench        3552         917       0.816       0.783        0.85       0.572\n",
      "              Pliers        3552        1592       0.846       0.845        0.89       0.595\n",
      "            Scissors        3552         661       0.667       0.511       0.568       0.301\n",
      "Speed: 12.4/1.9/14.3 ms inference/NMS/total per 640x640 image at batch-size 4\n",
      "Results saved to /content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False/yolov7_baggage_testing\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python /content/yolov7/test.py  \\\n",
    "--img 640 --batch {BATCH_SIZE} --conf 0.001 --iou 0.65 --device 0 \\\n",
    "--weights /content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False2/weights/best.pt \\\n",
    "--name yolov7_baggage_testing --data {DATA} \\\n",
    "--project {PROJECT}/{RUN_NAME} \\\n",
    "--task train"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGm9sKJcy2l0",
    "outputId": "da9838d5-848a-46b6-80d0-99d0df295eaf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(augment=False, batch_size=4, conf_thres=0.001, data='/content/yolov7/data/data_baggage.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='yolov7_baggage_testing', no_trace=False, project='/content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='train', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False2/weights/best.pt'])\n",
      "YOLOR üöÄ v0.1-121-g2fdc7f1 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15109.875MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 314 layers, 36508742 parameters, 6194944 gradients, 103.2 GFLOPS\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning '/content/yolov7_dataset/train/labels' images and labels... 6214 found, 0 missing, 1144 empty, 0 corrupted: 100% 6214/6214 [00:01<00:00, 3321.08it/s]\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: /content/yolov7_dataset/train/labels.cache\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1554/1554 [02:20<00:00, 11.03it/s]\n",
      "                 all        6214        9733       0.873       0.791       0.865       0.596\n",
      "                 Gun        6214        2501       0.974       0.962       0.985       0.735\n",
      "               Knife        6214        1618       0.925        0.75       0.883       0.582\n",
      "              Wrench        6214        1643       0.875       0.842        0.91       0.656\n",
      "              Pliers        6214        2850        0.89        0.88        0.93       0.652\n",
      "            Scissors        6214        1121       0.702       0.521       0.617       0.355\n",
      "Speed: 12.2/2.0/14.2 ms inference/NMS/total per 640x640 image at batch-size 4\n",
      "Results saved to /content/drive/MyDrive/Baggage/baggage_detection/Epochs:from70_cfg:yolov7_baggage.yaml_weights:last.pt_hyp:hyp.yaml_resize:False/yolov7_baggage_testing2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "9ZSYEtHq2RCl"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "8qRSfG7BjSP2",
    "I1CAtOd4bOxo",
    "7Uaio82jmwoL"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}